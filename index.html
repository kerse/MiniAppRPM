<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <title>Аватар Ready Player Me</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            position: relative;
        }

        canvas {
            display: block;
        }

        /* Стили для кнопки */
        #voiceButton {
            position: absolute;
            left: 50%;
            top: 80%;
            transform: translate(-50%, -50%);
            width: 150px;
            height: 150px;
            border-radius: 50%;
            background-color: #ffffff;
            border: none;
            font-size: 16px;
            cursor: pointer;
            text-align: center;
            vertical-align: middle;
            line-height: 150px; /* Центрирование текста по вертикали */
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
        }
    </style>
</head>
<body>
    <!-- Кнопка для голосового взаимодействия -->
    <button id="voiceButton">Нажмите, чтобы начать</button>

    <!-- Подключаем Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- Подключаем GLTFLoader для загрузки модели -->
    <script src="https://cdn.jsdelivr.net/npm/three@0.128/examples/js/loaders/GLTFLoader.js"></script>
    <!-- Подключаем OrbitControls для управления камерой -->
    <script src="https://cdn.jsdelivr.net/npm/three@0.128/examples/js/controls/OrbitControls.js"></script>

    <script>
        // Инициализация сцены и камеры
        const scene = new THREE.Scene();

        // Устанавливаем фон на глубокий фиолетовый цвет
        scene.background = new THREE.Color(0x4b0082); // Глубокий фиолетовый (индиго)

        const camera = new THREE.PerspectiveCamera(
            35, window.innerWidth / window.innerHeight, 0.1, 1000
        );
        camera.position.set(0, 1.75, 0.55); // Поднимаем камеру немного выше
        camera.lookAt(0, 1.7, 0); // Смотрим на центр головы

        // Инициализация рендерера
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        // Включаем тени
        renderer.shadowMap.enabled = true;
        document.body.appendChild(renderer.domElement);

        // Добавление стандартного освещения
        const hemiLight = new THREE.HemisphereLight(0xffffff, 0x444444, 1);
        hemiLight.position.set(0, 200, 0);
        scene.add(hemiLight);

        const dirLight = new THREE.DirectionalLight(0xffffff, 0.8);
        dirLight.position.set(0, 200, 100);
        dirLight.castShadow = true;
        scene.add(dirLight);

        // Инициализация контролов
        const controls = new THREE.OrbitControls(camera, renderer.domElement);
        controls.target.set(0, 1.7, 0);
        controls.update();

        let avatar; // Переменная для модели
        let morphTargets = []; // Массив морф-таргетов (для мимики)

        // Ссылка на модель аватара
        const avatarUrl = 'https://models.readyplayer.me/655e3008a0f45855e82ae649.glb';

        // Загрузка модели
        const loader = new THREE.GLTFLoader();
        loader.load(
            avatarUrl,
            function (gltf) {
                avatar = gltf.scene;

                // Включаем тени для модели
                avatar.traverse(function (node) {
                    if (node.isMesh) {
                        node.castShadow = true;
                        node.receiveShadow = true;

                        // Проверяем наличие морф-таргетов для мимики
                        if (node.morphTargetInfluences && node.morphTargetInfluences.length > 0) {
                            morphTargets.push(node);
                        }
                    }
                });

                scene.add(avatar);

                // Если найдены морф-таргеты, запускаем анимацию мимики
                if (morphTargets.length > 0) {
                    // animateMorphTargets(); // Отключено, так как мы будем управлять мимикой по аудио
                } else {
                    console.warn('Морф-таргеты не найдены в модели.');
                }

                animate();
            },
            undefined,
            function (error) {
                console.error('Ошибка при загрузке модели:', error);
            }
        );

        // Часы для отслеживания времени анимации
        const clock = new THREE.Clock();

        // Основная функция анимации
        function animate() {
            requestAnimationFrame(animate);

            const delta = clock.getDelta();

            controls.update(); // Обновляем контролы

            renderer.render(scene, camera);
        }

        // Обработка изменения размера окна
        window.addEventListener('resize', function () {
            const width = window.innerWidth;
            const height = window.innerHeight;
            renderer.setSize(width, height);
            camera.aspect = width / height;
            camera.updateProjectionMatrix();
        });

        // *** Добавляем функционал кнопки и голосового взаимодействия ***

        // Переменная для состояния и кнопки
        let connectionStatus = 'Нажмите, чтобы начать';
        const voiceButton = document.getElementById('voiceButton');
        voiceButton.innerText = connectionStatus;

        // Функция для обновления статуса на кнопке
        function updateStatus(status) {
            connectionStatus = status;
            voiceButton.innerText = status;
        }

        // Обработчик события нажатия на кнопку
        voiceButton.addEventListener('click', () => {
            // Начинаем голосовое взаимодействие через сервер
            startVoiceInteraction();
        });

        // Функция для установления связи с сервером и начала голосового взаимодействия
function startVoiceInteraction() {
    // Обновляем статус
    updateStatus('Подключаюсь к серверу...');

    // Подключаемся к локальному серверу
    const socket = new WebSocket('ws://localhost:8765'); // Используйте тот же порт, что и на сервере

    let mediaRecorder;

    socket.addEventListener('open', function (event) {
        updateStatus('Соединение установлено');

        // Захватываем аудио с микрофона
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(function (stream) {
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/ogg; codecs=opus' });

                mediaRecorder.ondataavailable = function (event) {
                    if (event.data.size > 0) {
                        // Читаем аудио-данные как Blob
                        const reader = new FileReader();
                        reader.onload = function () {
                            const arrayBuffer = reader.result;
                            // Конвертируем аудио-данные в Base64
                            const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));

                            // Отправляем аудио-данные на сервер
                            socket.send(JSON.stringify({
                                type: 'audio',
                                audio: base64Audio
                            }));
                        };
                        reader.readAsArrayBuffer(event.data);
                    }
                };

                mediaRecorder.start(250); // Отправляем аудио-данные каждые 250 мс

                updateStatus('Говорите...');

                // Останавливаем запись через определенное время или по событию
                setTimeout(() => {
                    mediaRecorder.stop();

                    // Сообщаем серверу об окончании аудио
                    socket.send(JSON.stringify({
                        type: 'audio_end'
                    }));
                }, 5000); // Останавливаем запись через 5 секунд
            })
            .catch(function (err) {
                console.error('Ошибка доступа к микрофону:', err);
                updateStatus('Ошибка доступа к микрофону');
            });
    });

    socket.addEventListener('message', function (event) {
        const data = JSON.parse(event.data);

        if (data.type === 'audio') {
            // Получаем аудио-данные от сервера и воспроизводим их
            const base64Audio = data.audio;
            const audioData = Uint8Array.from(atob(base64Audio), c => c.charCodeAt(0));

            const audioBlob = new Blob([audioData.buffer], { type: 'audio/ogg; codecs=opus' });
            const audioUrl = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioUrl);
            audio.play();

            // Дополнительно: управление мимикой по аудио (если требуется)
            // animateMorphTargets();
        } else if (data.type === 'text') {
            // Отображаем текстовые данные при необходимости
            console.log('Ассистент:', data.text);
        } else if (data.type === 'response_done') {
            // Обновляем статус при завершении ответа
            updateStatus('Нажмите, чтобы говорить');
        }
    });

    socket.addEventListener('error', function (event) {
        updateStatus('Ошибка соединения');
        console.error('WebSocket error:', event);
    });

    socket.addEventListener('close', function (event) {
        updateStatus('Соединение закрыто');
        console.log('WebSocket closed:', event);
    });
}


        // Функция для анимации мимики по аудио
        function animateMorphTargets() {
            if (morphTargets.length === 0) return;

            // Здесь вы можете реализовать анимацию морф-таргетов в зависимости от аудио
            // Например, открывать и закрывать рот при воспроизведении аудио

            // Пример простого открытия рта
            morphTargets.forEach(mesh => {
                if (mesh.morphTargetDictionary && mesh.morphTargetInfluences) {
                    const mouthOpenIndex = mesh.morphTargetDictionary['mouthOpen'];
                    if (typeof mouthOpenIndex !== 'undefined') {
                        // Устанавливаем влияние морф-таргета на 1 (максимум)
                        mesh.morphTargetInfluences[mouthOpenIndex] = 1;

                        // После короткой задержки закрываем рот
                        setTimeout(() => {
                            mesh.morphTargetInfluences[mouthOpenIndex] = 0;
                        }, 500); // Закрываем рот через 500 мс
                    }
                }
            });
        }

    </script>
</body>
</html>
